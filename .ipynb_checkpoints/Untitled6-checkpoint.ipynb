{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024ace5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49baa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imsave(image, path):\n",
    "  return scipy.misc.imsave(path, image)\n",
    "\n",
    "def merge(images, size):\n",
    "  h, w = images.shape[1], images.shape[2]\n",
    "  img = np.zeros((h*size[0], w*size[1], 1))\n",
    "  for idx, image in enumerate(images):\n",
    "    i = idx % size[1]\n",
    "    j = idx // size[1]\n",
    "    img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff8a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modcrop(image, scale=3):\n",
    "  \"\"\"\n",
    "  To scale down and up the original image, first thing to do is to have no remainder while scaling operation.\n",
    "  \n",
    "  We need to find modulo of height (and width) and scale factor.\n",
    "  Then, subtract the modulo from height (and width) of original image size.\n",
    "  There would be no remainder even after scaling operation.\n",
    "  \"\"\"\n",
    "  if len(image.shape) == 3:\n",
    "    h, w, _ = image.shape\n",
    "    h = h - np.mod(h, scale)\n",
    "    w = w - np.mod(w, scale)\n",
    "    image = image[0:h, 0:w, :]\n",
    "  else:\n",
    "    h, w = image.shape\n",
    "    h = h - np.mod(h, scale)\n",
    "    w = w - np.mod(w, scale)\n",
    "    image = image[0:h, 0:w]\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b026c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09945a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554ac12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path, scale=3):\n",
    "  \"\"\"\n",
    "  Preprocess single image file \n",
    "    (1) Read original image as YCbCr format (and grayscale as default)\n",
    "    (2) Normalize\n",
    "    (3) Apply image file with bicubic interpolation\n",
    "\n",
    "  Args:\n",
    "    path: file path of desired file\n",
    "    input_: image applied bicubic interpolation (low-resolution)\n",
    "    label_: image with original resolution (high-resolution)\n",
    "  \"\"\"\n",
    "  image = imread(path, is_grayscale=True)\n",
    "  label_ = modcrop(image, scale)\n",
    "\n",
    "  # Must be normalized\n",
    "  input_ = label_ / 255.\n",
    "  label_ = label_ / 255.\n",
    "\n",
    "  #input_ = scipy.ndimage.interpolation.zoom(label_, (1./scale), prefilter=False)\n",
    "  #input_ = scipy.ndimage.interpolation.zoom(input_, (scale/1.), prefilter=False)\n",
    "\n",
    "  return input_, label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880373f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def input_setup(config):\n",
    "    \"\"\"\n",
    "    Read image files from a directory and create sub-images for training or testing.\n",
    "    \"\"\"\n",
    "    # Load data path\n",
    "    if config.is_train:\n",
    "        data_path = os.path.join(config.dataset_path, \"Train\")\n",
    "    else:\n",
    "        data_path = os.path.join(config.dataset_path, \"Test\")\n",
    "\n",
    "    image_files = [os.path.join(data_path, f) for f in os.listdir(data_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    sub_input_sequence = []\n",
    "    sub_label_sequence = []\n",
    "    padding = abs(config.image_size - config.label_size) // 2  # Typically 0 if sizes are the same\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    if config.is_train:\n",
    "        for img_file in image_files:\n",
    "            input_, label_ = preprocess(img_file, config.scale, transform)\n",
    "\n",
    "            if input_.ndim == 3:\n",
    "                h, w, _ = input_.shape\n",
    "            else:\n",
    "                h, w = input_.shape\n",
    "\n",
    "            for x in range(0, h - config.image_size + 1, config.stride):\n",
    "                for y in range(0, w - config.image_size + 1, config.stride):\n",
    "                    sub_input = input_[:, x:x + config.image_size, y:y + config.image_size]  # [3 x 33 x 33]\n",
    "                    sub_label = label_[:, x + padding:x + padding + config.label_size, y + padding:y + padding + config.label_size]  # [3 x 33 x 33]\n",
    "\n",
    "                    sub_input_sequence.append(sub_input)\n",
    "                    sub_label_sequence.append(sub_label)\n",
    "\n",
    "        # Shuffle\n",
    "        combined = list(zip(sub_input_sequence, sub_label_sequence))\n",
    "        random.shuffle(combined)\n",
    "        sub_input_sequence, sub_label_sequence = zip(*combined)\n",
    "        sub_input_sequence = torch.stack(sub_input_sequence)\n",
    "        sub_label_sequence = torch.stack(sub_label_sequence)\n",
    "\n",
    "    else:\n",
    "        input_init, label_init = preprocess(image_files[2], config.scale, transform)  # Choose a specific image for testing\n",
    "\n",
    "        if input_init.ndim == 3:\n",
    "            h, w, _ = input_init.shape\n",
    "        else:\n",
    "            h, w = input_init.shape\n",
    "\n",
    "        pad_h = config.image_size - divmod(h, config.image_size)[1]\n",
    "        pad_w = config.image_size - divmod(w, config.image_size)[1]\n",
    "        input_ = np.pad(input_init, ((0, pad_h), (0, pad_w), (0, 0)), 'symmetric')\n",
    "        label_ = input_\n",
    "        h = h + pad_h\n",
    "        w = w + pad_w\n",
    "\n",
    "        nx = ny = 0\n",
    "        for x in range(0, h - config.image_size + 1, config.stride):\n",
    "            nx += 1\n",
    "            ny = 0\n",
    "            for y in range(0, w - config.image_size + 1, config.stride):\n",
    "                ny += 1\n",
    "                sub_input = input_[:, x:x + config.image_size, y:y + config.image_size]  # [3 x 33 x 33]\n",
    "                sub_label = label_[:, x + padding:x + padding + config.label_size, y + padding:y + padding + config.label_size]  # [3 x 33 x 33]\n",
    "\n",
    "                sub_input_sequence.append(sub_input)\n",
    "                sub_label_sequence.append(sub_label)\n",
    "\n",
    "        sub_input_sequence = torch.stack(sub_input_sequence)\n",
    "        sub_label_sequence = torch.stack(sub_label_sequence)\n",
    "\n",
    "        return sub_input_sequence, sub_label_sequence, nx, ny, pad_h, pad_w\n",
    "\n",
    "    return sub_input_sequence, sub_label_sequence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dcdac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ca0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    is_train = True\n",
    "    dataset_path = './images/BSDS200'\n",
    "    image_size = 33\n",
    "    label_size = 33\n",
    "    scale = 1\n",
    "    stride = 14\n",
    "    epoch = 2\n",
    "    checkpoint_dir = './new_checkpoints'\n",
    "\n",
    "config = Config()\n",
    "train_inputs, train_labels = input_setup(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e3091",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_inputs.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a9ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e8212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f2778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d502dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486598c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def train(model, config):\n",
    "    # Prepare data\n",
    "    if config.is_train:\n",
    "        sub_input_sequence, sub_label_sequence = input_setup(config)\n",
    "    else:\n",
    "        sub_input_sequence, sub_label_sequence, nx, ny, pad_h, pad_w = input_setup(config)\n",
    "\n",
    "    train_data = torch.stack(sub_input_sequence).to(model.device)\n",
    "    train_label = torch.stack(sub_label_sequence).to(model.device)\n",
    "\n",
    "    dataset = TensorDataset(train_data, train_label)\n",
    "    data_loader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    model.model.train()\n",
    "    start_time = time.time()\n",
    "\n",
    "    if model.load(config.checkpoint_dir):\n",
    "        print(\" [*] Load SUCCESS\")\n",
    "    else:\n",
    "        print(\" [!] Load failed...\")\n",
    "\n",
    "    if config.is_train:\n",
    "        print(\"Training...\")\n",
    "\n",
    "        for ep in range(config.epoch):\n",
    "            for idx, (batch_images, batch_labels) in enumerate(data_loader):\n",
    "                model.optimizer.zero_grad()\n",
    "                outputs = model.model(batch_images)\n",
    "                loss = model.criterion(outputs, batch_labels)\n",
    "                loss.backward()\n",
    "                model.optimizer.step()\n",
    "\n",
    "                if idx % 10 == 0:\n",
    "                    print(f\"Epoch: [{ep+1}/{config.epoch}], Step: [{idx}/{len(data_loader)}], \"\n",
    "                          f\"Time: [{time.time() - start_time:.4f}], Loss: [{loss.item():.8f}]\")\n",
    "\n",
    "                if idx % 500 == 0:\n",
    "                    model.save(config.checkpoint_dir, idx)\n",
    "\n",
    "    else:\n",
    "        print(\"Testing...\")\n",
    "        model.model.eval()\n",
    "        with torch.no_grad():\n",
    "            results = model.model(train_data)\n",
    "            results = results.cpu()\n",
    "\n",
    "        results = results.numpy()\n",
    "        results = merge(results, [nx, ny])\n",
    "        results = results.squeeze()\n",
    "\n",
    "        # Change back to original size\n",
    "        h, w = np.shape(results)\n",
    "        results = results[0:(h - pad_h), 0:(w - pad_w)]\n",
    "#         image_path = os.path.join(os.getcwd(), config.sample_dir, \"test.png\")\n",
    "#         os.makedirs(os.path.dirname(image_path), exist_ok=True)\n",
    "#         save_image(torch.tensor(results), image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "model = Model(config)\n",
    "train(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a74e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f345a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83780383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
