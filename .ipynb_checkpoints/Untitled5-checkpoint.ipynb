{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394acb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39289c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44a596a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/shivam/anaconda3/lib/python3.8/site-packages/torch/lib/libtorch_cuda_cpp.so: undefined symbol: cudaGraphRetainUserObject, version libcudart.so.11.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6803/2505357863.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/shivam/anaconda3/lib/python3.8/site-packages/torch/lib/libtorch_cuda_cpp.so: undefined symbol: cudaGraphRetainUserObject, version libcudart.so.11.0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.is_train = True\n",
    "        self.image_size = 33\n",
    "        self.label_size = 33\n",
    "        self.scale = 2\n",
    "        self.stride = 14\n",
    "        self.batch_size = 128\n",
    "        self.learning_rate = 1e-4\n",
    "        self.epoch = 10\n",
    "        self.checkpoint_dir = './checkpoint'\n",
    "        self.sample_dir = './sample'\n",
    "\n",
    "config = Config()\n",
    "\n",
    "def imread(path, is_grayscale=True):\n",
    "    if is_grayscale:\n",
    "        return np.array(Image.open(path).convert('YCbCr').split()[0], dtype=np.float32)\n",
    "    else:\n",
    "        return np.array(Image.open(path).convert('YCbCr'), dtype=np.float32)\n",
    "\n",
    "def modcrop(image, scale=3):\n",
    "    h, w = image.shape\n",
    "    h = h - np.mod(h, scale)\n",
    "    w = w - np.mod(w, scale)\n",
    "    return image[0:h, 0:w]\n",
    "\n",
    "def preprocess(image_path, scale=3):\n",
    "    image = imread(image_path, is_grayscale=True)\n",
    "    label_ = modcrop(image, scale)\n",
    "    input_ = label_ / 255.0\n",
    "    label_ = label_ / 255.0\n",
    "    return input_, label_\n",
    "\n",
    "def input_setup(config, image_path):\n",
    "    input_, label_ = preprocess(image_path, config.scale)\n",
    "    sub_input_sequence = []\n",
    "    sub_label_sequence = []\n",
    "\n",
    "    padding = abs(config.image_size - config.label_size) // 2\n",
    "\n",
    "    h, w = input_.shape\n",
    "\n",
    "    for x in range(0, h - config.image_size + 1, config.stride):\n",
    "        for y in range(0, w - config.image_size + 1, config.stride):\n",
    "            sub_input = input_[x:x + config.image_size, y:y + config.image_size]\n",
    "            sub_label = label_[x + padding:x + padding + config.label_size, y + padding:y + padding + config.label_size]\n",
    "\n",
    "            sub_input = sub_input.reshape([config.image_size, config.image_size, 1])\n",
    "            sub_label = sub_label.reshape([config.label_size, config.label_size, 1])\n",
    "\n",
    "            sub_input_sequence.append(sub_input)\n",
    "            sub_label_sequence.append(sub_label)\n",
    "\n",
    "    sub_input_sequence = np.array(sub_input_sequence)\n",
    "    sub_label_sequence = np.array(sub_label_sequence)\n",
    "\n",
    "    return sub_input_sequence, sub_label_sequence\n",
    "\n",
    "def imsave(image, path):\n",
    "    Image.fromarray(image.astype(np.uint8)).save(path)\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 1))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j * h:j * h + h, i * w:i * w + w, :] = image\n",
    "\n",
    "    return img\n",
    "\n",
    "# PyTorch Dataset class for handling image data\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, config):\n",
    "        self.image_paths = image_paths\n",
    "        self.config = config\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        sub_input_sequence, sub_label_sequence = input_setup(self.config, image_path)\n",
    "        return torch.tensor(sub_input_sequence, dtype=torch.float32).permute(0, 3, 1, 2), \\\n",
    "               torch.tensor(sub_label_sequence, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "\n",
    "# Load images from a directory\n",
    "def prepare_data(dataset):\n",
    "    filenames = [os.path.join(dataset, file) for file in os.listdir(dataset) if file.endswith('.png')]\n",
    "    return filenames\n",
    "\n",
    "# Main code to run the setup\n",
    "dataset_path = \"./images\"  # Directory containing images\n",
    "image_paths = prepare_data(dataset_path)\n",
    "dataset = ImageDataset(image_paths, config)\n",
    "data_loader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "# To visualize the first sub-image and its label\n",
    "sample_input, sample_label = dataset[0]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(sample_input[0][0].numpy(), cmap='gray')\n",
    "plt.title('Sub-input')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(sample_label[0][0].numpy(), cmap='gray')\n",
    "plt.title('Sub-label')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a399d2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/shivam/anaconda3/lib/python3.8/site-packages/torch/lib/libtorch_cuda_cpp.so: undefined symbol: cudaGraphRetainUserObject, version libcudart.so.11.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6803/1629461014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/shivam/anaconda3/lib/python3.8/site-packages/torch/lib/libtorch_cuda_cpp.so: undefined symbol: cudaGraphRetainUserObject, version libcudart.so.11.0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from math import ceil\n",
    "from skimage.io import imsave\n",
    "from skimage.util import view_as_windows\n",
    "\n",
    "# Helper functions\n",
    "def input_setup(config, image_path):\n",
    "    # Assuming images are already loaded as numpy arrays\n",
    "    image = np.load(image_path)  # Load your image as a numpy array\n",
    "    sub_input_sequence = []\n",
    "    sub_label_sequence = []\n",
    "\n",
    "    padding = abs(config.image_size - config.label_size) // 2\n",
    "    padded_image = np.pad(image, ((padding, padding), (padding, padding), (0, 0)), 'constant')\n",
    "\n",
    "    for x in range(0, padded_image.shape[0] - config.image_size + 1, config.stride):\n",
    "        for y in range(0, padded_image.shape[1] - config.image_size + 1, config.stride):\n",
    "            sub_input = padded_image[x:x + config.image_size, y:y + config.image_size]\n",
    "            sub_label = padded_image[x + padding:x + padding + config.label_size,\n",
    "                                     y + padding:y + padding + config.label_size]\n",
    "            sub_input_sequence.append(sub_input)\n",
    "            sub_label_sequence.append(sub_label)\n",
    "\n",
    "    return np.asarray(sub_input_sequence), np.asarray(sub_label_sequence)\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], images.shape[3]))\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "\n",
    "    return img\n",
    "\n",
    "class RECONNET(nn.Module):\n",
    "    def __init__(self, image_size=33, label_size=33, measurement_rate=1e-1, c_dim=1):\n",
    "        super(RECONNET, self).__init__()\n",
    "        self.fc_size = int(ceil(measurement_rate * 1089))\n",
    "        \n",
    "        self.fc1 = nn.Linear(1089, self.fc_size)\n",
    "        self.fc2 = nn.Linear(self.fc_size, 1089)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=11, padding=5)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=7, padding=3)\n",
    "        self.conv4 = nn.Conv2d(1, 64, kernel_size=11, padding=5)\n",
    "        self.conv5 = nn.Conv2d(64, 32, kernel_size=1)\n",
    "        self.conv6 = nn.Conv2d(32, 1, kernel_size=7, padding=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1089)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = x.view(-1, 1, 33, 33)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = torch.relu(self.conv5(x))\n",
    "        x = self.conv6(x)\n",
    "        return x\n",
    "\n",
    "def train(config, model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for epoch in range(config.epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch: [{epoch+1}], step: [{batch_idx}], time: [{time.time() - start_time:.4f}], loss: [{loss.item():.8f}]\")\n",
    "            if batch_idx % 500 == 0:\n",
    "                torch.save(model.state_dict(), os.path.join(config.checkpoint_dir, f'model_epoch_{epoch+1}_step_{batch_idx}.pth'))\n",
    "\n",
    "def test(config, model, device, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            result = output.cpu().numpy()\n",
    "            nx = ny = int(np.sqrt(len(result)))\n",
    "            result = merge(result, [nx, ny])\n",
    "            result = result.squeeze()\n",
    "            image_path = os.path.join(config.sample_dir, \"test.png\")\n",
    "            imsave(image_path, result)\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.is_train = True\n",
    "        self.image_size = 33\n",
    "        self.label_size = 33\n",
    "        self.scale = 2\n",
    "        self.stride = 14\n",
    "        self.epoch = 10\n",
    "        self.batch_size = 128\n",
    "        self.learning_rate = 1e-4\n",
    "        self.checkpoint_dir = './checkpoint'\n",
    "        self.sample_dir = './sample'\n",
    "\n",
    "# Main code to run the setup\n",
    "config = Config()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load your data as numpy arrays\n",
    "image_path = \"./images/test1.npy\"  # Path to numpy array of the image\n",
    "train_data, train_label = input_setup(config, image_path)\n",
    "\n",
    "train_dataset = data.TensorDataset(torch.tensor(train_data, dtype=torch.float32).permute(0, 3, 1, 2), \n",
    "                                   torch.tensor(train_label, dtype=torch.float32).permute(0, 3, 1, 2))\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "model = RECONNET(image_size=config.image_size, label_size=config.label_size).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=0.9)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if config.is_train:\n",
    "    train(config, model, device, train_loader, optimizer, criterion)\n",
    "else:\n",
    "    test(config, model, device, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b29aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b281d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22538154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
