{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861798dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from TrainDataset import TrainDataset\n",
    "from TestDataset import TestDataset\n",
    "#from model import ReconNet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline\n",
    "from utils import resize_image, restore_image\n",
    "#from ourModel import Model\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b11a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './images/all_images/BSDS200'\n",
    "compression_percentage = 1\n",
    "test_file_name = 'test1.png'\n",
    "num_epochs = 200\n",
    "\n",
    "#name='Our_new_model_2fclayer_200_epoch_' + str(compression_percentage) + '_compression_rate'\n",
    "name='Reconnet_original_200_epoch_' + str(compression_percentage) + '_compression_rate'\n",
    "original_image = './images/test_sample_' + name + '.png'\n",
    "sample_image = './images/sample_result_' + name + '.png'\n",
    "model_name = 'model_state_'+ name +'.pth'\n",
    "log_file_name = 'model_state_'+ name +'.txt'\n",
    "compression_rate = compression_percentage/100\n",
    "ratio_dict = {1: 10, 4: 43, 10: 109, 20: 218, 25: 272, 30: 327, 40: 436, 50: 545}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc1a653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78bfb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    return v / np.sqrt(v.dot(v))\n",
    "\n",
    "def generate_phi(x, y):\n",
    "    np.random.seed(333)\n",
    "    phi = np.random.normal(size=(x, y))\n",
    "    n = len(phi)\n",
    "    \n",
    "    # Perform Gram-Schmidt orthonormalization\n",
    "    phi[0, :] = normalize(phi[0, :])\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        Ai = phi[i, :]\n",
    "        for j in range(0, i):\n",
    "            Aj = phi[j, :]\n",
    "            t = Ai.dot(Aj)\n",
    "            Ai = Ai - t * Aj\n",
    "        phi[i, :] = normalize(Ai)\n",
    "        \n",
    "    return phi\n",
    "\n",
    "mat = generate_phi(ratio_dict[compression_percentage], 1089)\n",
    "mat = torch.from_numpy(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be9d4be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (fc1): Linear(in_features=10, out_features=1089, bias=True)\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv5): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv6): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = TrainDataset(path,mat,transformations,compression_rate)\n",
    "\n",
    "train_dl = DataLoader(train_data,batch_size=128)\n",
    "\n",
    "train_iter = iter(train_dl)\n",
    "images , labels = next(train_iter)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "model = Model(ratio_dict, compression_percentage, measurement_rate=compression_rate)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67eb89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "# Create directories to save models and logs\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "def train(model, criterion, optimizer, train_dl, num_epochs=10, scheduler=None, early_stopping_patience=10, log_file_name='training_log.txt'):\n",
    "    best_train_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Move model to CUDA device once\n",
    "    model = model.cuda()\n",
    "    \n",
    "    print(model)\n",
    "\n",
    "    # Open the log file\n",
    "    log_file_path = os.path.join('logs', log_file_name)\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "        log_file.write(str(model) + '\\n\\n')\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            start_time = time.time()\n",
    "            train_loss = []\n",
    "            psnr_values = []\n",
    "            model.train()\n",
    "\n",
    "            for inp, lbl in train_dl:\n",
    "                inp = inp.cuda().float()\n",
    "                lbl = lbl.cuda().float()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                out = model(inp)\n",
    "                out = out.view(lbl.size())\n",
    "                loss = criterion(out, lbl)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "                # Calculate PSNR\n",
    "                out_cpu = out.detach().cpu().numpy()\n",
    "                lbl_cpu = lbl.detach().cpu().numpy()\n",
    "                psnr_values.append(psnr(lbl_cpu, out_cpu))\n",
    "\n",
    "            epoch_time = time.time() - start_time\n",
    "            total_time = time.time() - total_start_time  # Total time taken for all epochs so far\n",
    "\n",
    "            mean_train_loss = np.mean(train_loss)\n",
    "            mean_psnr = np.mean(psnr_values)\n",
    "\n",
    "            log_message = (f'Epoch: {epoch+1}/{num_epochs}, Training Loss: {mean_train_loss:.10f}, '\n",
    "                           f'PSNR: {mean_psnr:.4f}, Time taken: {epoch_time:.2f} seconds, '\n",
    "                           f'Total time taken: {total_time:.2f} seconds\\n')\n",
    "\n",
    "            print(log_message)\n",
    "            log_file.write(log_message)\n",
    "\n",
    "            # Save the best model\n",
    "            if mean_train_loss < best_train_loss:\n",
    "                best_train_loss = mean_train_loss\n",
    "                patience_counter = 0\n",
    "                model_path = os.path.join('saved_models', f'best_model_epoch_{epoch+1}.pth')\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                save_message = f\"Saved best model at epoch {epoch+1} with training loss: {mean_train_loss:.6f}\\n\"\n",
    "                print(save_message)\n",
    "                log_file.write(save_message)\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= early_stopping_patience:\n",
    "                    early_stop_message = \"Early stopping triggered\\n\"\n",
    "                    print(early_stop_message)\n",
    "                    log_file.write(early_stop_message)\n",
    "                    break\n",
    "\n",
    "            # Learning rate scheduler\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "        total_duration = time.time() - total_start_time\n",
    "        completion_message = f\"Training completed in: {total_duration:.2f} seconds\\n\"\n",
    "        print(completion_message)\n",
    "        log_file.write(completion_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4a0c49d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (fc1): Linear(in_features=10, out_features=1089, bias=True)\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv5): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv6): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 1/200, Training Loss: 0.0253394695, PSNR: 18.3993, Time taken: 30.82 seconds, Total time taken: 35.44 seconds\n",
      "\n",
      "Saved best model at epoch 1 with training loss: 0.025339\n",
      "\n",
      "Epoch: 2/200, Training Loss: 0.0165371638, PSNR: 19.7381, Time taken: 31.06 seconds, Total time taken: 66.50 seconds\n",
      "\n",
      "Saved best model at epoch 2 with training loss: 0.016537\n",
      "\n",
      "Epoch: 3/200, Training Loss: 0.0162802115, PSNR: 19.8242, Time taken: 31.13 seconds, Total time taken: 97.64 seconds\n",
      "\n",
      "Saved best model at epoch 3 with training loss: 0.016280\n",
      "\n",
      "Epoch: 4/200, Training Loss: 0.0161162509, PSNR: 19.8653, Time taken: 31.24 seconds, Total time taken: 128.88 seconds\n",
      "\n",
      "Saved best model at epoch 4 with training loss: 0.016116\n",
      "\n",
      "Epoch: 5/200, Training Loss: 0.0160355545, PSNR: 19.8815, Time taken: 31.15 seconds, Total time taken: 160.03 seconds\n",
      "\n",
      "Saved best model at epoch 5 with training loss: 0.016036\n",
      "\n",
      "Epoch: 6/200, Training Loss: 0.0154729592, PSNR: 20.1835, Time taken: 31.21 seconds, Total time taken: 191.24 seconds\n",
      "\n",
      "Saved best model at epoch 6 with training loss: 0.015473\n",
      "\n",
      "Epoch: 7/200, Training Loss: 0.0154563818, PSNR: 20.1890, Time taken: 31.16 seconds, Total time taken: 222.41 seconds\n",
      "\n",
      "Saved best model at epoch 7 with training loss: 0.015456\n",
      "\n",
      "Epoch: 8/200, Training Loss: 0.0154506977, PSNR: 20.1896, Time taken: 31.16 seconds, Total time taken: 253.57 seconds\n",
      "\n",
      "Saved best model at epoch 8 with training loss: 0.015451\n",
      "\n",
      "Epoch: 9/200, Training Loss: 0.0154407569, PSNR: 20.1933, Time taken: 31.19 seconds, Total time taken: 284.77 seconds\n",
      "\n",
      "Saved best model at epoch 9 with training loss: 0.015441\n",
      "\n",
      "Epoch: 10/200, Training Loss: 0.0154295740, PSNR: 20.1979, Time taken: 31.18 seconds, Total time taken: 315.95 seconds\n",
      "\n",
      "Saved best model at epoch 10 with training loss: 0.015430\n",
      "\n",
      "Epoch: 11/200, Training Loss: 0.0153229168, PSNR: 20.2673, Time taken: 31.19 seconds, Total time taken: 347.17 seconds\n",
      "\n",
      "Saved best model at epoch 11 with training loss: 0.015323\n",
      "\n",
      "Epoch: 12/200, Training Loss: 0.0153172354, PSNR: 20.2706, Time taken: 31.24 seconds, Total time taken: 378.41 seconds\n",
      "\n",
      "Saved best model at epoch 12 with training loss: 0.015317\n",
      "\n",
      "Epoch: 13/200, Training Loss: 0.0153155158, PSNR: 20.2711, Time taken: 31.26 seconds, Total time taken: 409.67 seconds\n",
      "\n",
      "Saved best model at epoch 13 with training loss: 0.015316\n",
      "\n",
      "Epoch: 14/200, Training Loss: 0.0153137719, PSNR: 20.2718, Time taken: 31.24 seconds, Total time taken: 440.92 seconds\n",
      "\n",
      "Saved best model at epoch 14 with training loss: 0.015314\n",
      "\n",
      "Epoch: 15/200, Training Loss: 0.0153120256, PSNR: 20.2725, Time taken: 31.24 seconds, Total time taken: 472.16 seconds\n",
      "\n",
      "Saved best model at epoch 15 with training loss: 0.015312\n",
      "\n",
      "Epoch: 16/200, Training Loss: 0.0153061293, PSNR: 20.2796, Time taken: 31.24 seconds, Total time taken: 503.40 seconds\n",
      "\n",
      "Saved best model at epoch 16 with training loss: 0.015306\n",
      "\n",
      "Epoch: 17/200, Training Loss: 0.0153055504, PSNR: 20.2803, Time taken: 31.29 seconds, Total time taken: 534.70 seconds\n",
      "\n",
      "Saved best model at epoch 17 with training loss: 0.015306\n",
      "\n",
      "Epoch: 18/200, Training Loss: 0.0153052217, PSNR: 20.2804, Time taken: 31.23 seconds, Total time taken: 565.93 seconds\n",
      "\n",
      "Saved best model at epoch 18 with training loss: 0.015305\n",
      "\n",
      "Epoch: 19/200, Training Loss: 0.0153049670, PSNR: 20.2805, Time taken: 31.24 seconds, Total time taken: 597.18 seconds\n",
      "\n",
      "Saved best model at epoch 19 with training loss: 0.015305\n",
      "\n",
      "Epoch: 20/200, Training Loss: 0.0153047465, PSNR: 20.2806, Time taken: 31.27 seconds, Total time taken: 628.46 seconds\n",
      "\n",
      "Saved best model at epoch 20 with training loss: 0.015305\n",
      "\n",
      "Epoch: 21/200, Training Loss: 0.0153036754, PSNR: 20.2820, Time taken: 31.31 seconds, Total time taken: 659.78 seconds\n",
      "\n",
      "Saved best model at epoch 21 with training loss: 0.015304\n",
      "\n",
      "Epoch: 22/200, Training Loss: 0.0153036449, PSNR: 20.2820, Time taken: 31.27 seconds, Total time taken: 691.04 seconds\n",
      "\n",
      "Saved best model at epoch 22 with training loss: 0.015304\n",
      "\n",
      "Epoch: 23/200, Training Loss: 0.0153036201, PSNR: 20.2820, Time taken: 31.24 seconds, Total time taken: 722.28 seconds\n",
      "\n",
      "Saved best model at epoch 23 with training loss: 0.015304\n",
      "\n",
      "Epoch: 24/200, Training Loss: 0.0153035974, PSNR: 20.2820, Time taken: 31.27 seconds, Total time taken: 753.56 seconds\n",
      "\n",
      "Saved best model at epoch 24 with training loss: 0.015304\n",
      "\n",
      "Epoch: 25/200, Training Loss: 0.0153035756, PSNR: 20.2820, Time taken: 31.21 seconds, Total time taken: 784.77 seconds\n",
      "\n",
      "Saved best model at epoch 25 with training loss: 0.015304\n",
      "\n",
      "Epoch: 26/200, Training Loss: 0.0153033395, PSNR: 20.2820, Time taken: 31.20 seconds, Total time taken: 815.97 seconds\n",
      "\n",
      "Saved best model at epoch 26 with training loss: 0.015303\n",
      "\n",
      "Epoch: 27/200, Training Loss: 0.0153033378, PSNR: 20.2820, Time taken: 31.20 seconds, Total time taken: 847.18 seconds\n",
      "\n",
      "Saved best model at epoch 27 with training loss: 0.015303\n",
      "\n",
      "Epoch: 28/200, Training Loss: 0.0153033360, PSNR: 20.2820, Time taken: 31.22 seconds, Total time taken: 878.39 seconds\n",
      "\n",
      "Saved best model at epoch 28 with training loss: 0.015303\n",
      "\n",
      "Epoch: 29/200, Training Loss: 0.0153033343, PSNR: 20.2820, Time taken: 31.28 seconds, Total time taken: 909.67 seconds\n",
      "\n",
      "Saved best model at epoch 29 with training loss: 0.015303\n",
      "\n",
      "Epoch: 30/200, Training Loss: 0.0153033326, PSNR: 20.2820, Time taken: 31.24 seconds, Total time taken: 940.91 seconds\n",
      "\n",
      "Saved best model at epoch 30 with training loss: 0.015303\n",
      "\n",
      "Epoch: 31/200, Training Loss: 0.0153033121, PSNR: 20.2820, Time taken: 31.25 seconds, Total time taken: 972.17 seconds\n",
      "\n",
      "Saved best model at epoch 31 with training loss: 0.015303\n",
      "\n",
      "Epoch: 32/200, Training Loss: 0.0153033120, PSNR: 20.2820, Time taken: 31.28 seconds, Total time taken: 1003.45 seconds\n",
      "\n",
      "Saved best model at epoch 32 with training loss: 0.015303\n",
      "\n",
      "Epoch: 33/200, Training Loss: 0.0153033121, PSNR: 20.2820, Time taken: 31.26 seconds, Total time taken: 1034.71 seconds\n",
      "\n",
      "Epoch: 34/200, Training Loss: 0.0153033121, PSNR: 20.2820, Time taken: 31.22 seconds, Total time taken: 1065.93 seconds\n",
      "\n",
      "Epoch: 35/200, Training Loss: 0.0153033119, PSNR: 20.2820, Time taken: 31.25 seconds, Total time taken: 1097.18 seconds\n",
      "\n",
      "Saved best model at epoch 35 with training loss: 0.015303\n",
      "\n",
      "Epoch: 36/200, Training Loss: 0.0153033117, PSNR: 20.2820, Time taken: 31.29 seconds, Total time taken: 1128.47 seconds\n",
      "\n",
      "Saved best model at epoch 36 with training loss: 0.015303\n",
      "\n",
      "Epoch: 37/200, Training Loss: 0.0153033117, PSNR: 20.2820, Time taken: 31.23 seconds, Total time taken: 1159.70 seconds\n",
      "\n",
      "Epoch: 38/200, Training Loss: 0.0153033117, PSNR: 20.2820, Time taken: 31.23 seconds, Total time taken: 1190.93 seconds\n",
      "\n",
      "Epoch: 39/200, Training Loss: 0.0153033117, PSNR: 20.2820, Time taken: 31.27 seconds, Total time taken: 1222.19 seconds\n",
      "\n",
      "Epoch: 40/200, Training Loss: 0.0153033117, PSNR: 20.2820, Time taken: 31.29 seconds, Total time taken: 1253.48 seconds\n",
      "\n",
      "Epoch: 41/200, Training Loss: 0.0153033117, PSNR: 20.2820, Time taken: 31.24 seconds, Total time taken: 1284.72 seconds\n",
      "\n",
      "Saved best model at epoch 41 with training loss: 0.015303\n",
      "\n",
      "Epoch: 42/200, Training Loss: 0.0153033116, PSNR: 20.2820, Time taken: 31.27 seconds, Total time taken: 1315.99 seconds\n",
      "\n",
      "Saved best model at epoch 42 with training loss: 0.015303\n",
      "\n",
      "Epoch: 43/200, Training Loss: 0.0153033116, PSNR: 20.2820, Time taken: 31.22 seconds, Total time taken: 1347.22 seconds\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4287/3085436299.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_patience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_file_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4287/1733357811.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_dl, num_epochs, scheduler, early_stopping_patience, log_file_name)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# Calculate PSNR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mout_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mlbl_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mpsnr_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, criterion, optimizer, train_dl, num_epochs=200, scheduler=scheduler, early_stopping_patience=10, log_file_name=log_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef57e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model_name = './saved_models/best_model_epoch_133.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394cf27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0b6481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab9f194f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (fc1): Linear(in_features=10, out_features=1089, bias=True)\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv6): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(model_name,map_location ='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca862e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33342f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
